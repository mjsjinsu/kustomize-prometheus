apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: prometheus
    prometheus: cluster
  name: rule-kube-state-metrics
  namespace: kube-system
spec:
  groups:
  - name: kube-state-metrics.rules
    rules:
    - alert: K8SNodeNotReady
      annotations:
        description: The Kubelet on {{ $labels.node }} has not checked in with the API, or has set itself to NotReady, for more than 2m
        summary: Node status is NotReady
      expr: kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: critical
    - alert: K8SNodeOutOfDisk
      annotations:
        description: '{{ $labels.node }} is insufficient free space on the node for adding new pods'
        summary: Node ran out of disk space.
      expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
    - alert: K8SNodeMemoryPressure
      annotations:
        description: '{{ $labels.node }} memory is low'
        summary: Node is under memory pressure.
      expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
    - alert: K8SNodePIDPressure
      expr: kube_node_status_condition{condition="PIDPressure",status="true"} == 1
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: "{{ $labels.node }} is too many processes on the node"
        summary: Node is under PID pressure.
    - alert: K8SNodeDiskPressure
      expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: "{{ $labels.node }} disk capacity is low"
        summary: Node is under disk pressure.
    - alert: K8SCPUOvercommit
      expr: 100 * sum(kube_pod_container_resource_requests_cpu_cores) by (node) / sum(kube_node_status_allocatable_cpu_cores) by (node) > 90
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: '{{ $labels.node }} has overcommitted CPU resource requests for Pods and cannot tolerate node failure'
        summary: Node is under CPU Overcommit
    - alert: K8SMemoryOvercommit
      expr: 100 * sum(kube_pod_container_resource_requests_memory_bytes) by (node) / sum(kube_node_status_allocatable_memory_bytes) by (node) > 90
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: '{{ $labels.node }} has overcommitted memory resource requests for Pods and cannot tolerate node failure'
        summary: Node is under Memory Overcommit
    - alert: PodFrequentlyRestarting
      expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
      for: 10m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        summary: Pod is restarting frequently
        description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} is was restarted {{ $value }} times within the last hour'
    - alert: JobFailed
      expr: kube_job_status_failed{job="kube-state-metrics"} > 0
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: Job '{{ $labels.namespace }}/{{ $labels.job }} has failed for some reason' 
        summary: Job has failed
    - alert: PodStatusWaiting
      expr: kube_pod_container_status_waiting_reason{reason!="ContainerCreating"} > 0 
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: Pod '{{ $labels.pod }} in namespace {{ $labels.namespace }} has a waiting status due to {{ $labels.reason }}'
        summary: Pod status waiting 
    - alert: PodStatusTerminated
      expr: kube_pod_container_status_terminated_reason{reason!="Completed"} > 0
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: 'Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has a termination status due to {{ $labels.reason }}'
        summary: Pod was terminated status
    - alert: PodNotReady 
      expr: sum by (namespace, pod, phase) (kube_pod_status_phase{job="kube-state-metrics", phase!="Running", phase!="Succeeded"}) > 0
      for: 1h
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour'
        summary: Pod has non-ready status
    - alert: DaemonSetsMissScheduled
      expr: kube_daemonset_status_number_misscheduled > 0
      for: 10m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: 'A number of daemonsets {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run'
        summary: Daemonsets are not scheduled correctly
    - alert: K8SQuotaExceeded
      expr: 100 * kube_resourcequota{job="kube-state-metrics", type="used"} / ignoring(instance, job, type) (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0) > 90
      for: 2m
      labels:
        channel: sk-cps-ops
        severity: warning
      annotations:
        description: 'Namespace {{ $labels.namespace }} is using {{ printf "%0.0f" $value }}% of its {{ $labels.resource }} quota'
        summary: Namespace Quota wil be Exceeded
